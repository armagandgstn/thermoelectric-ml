# -*- coding: utf-8 -*-
"""final PLots with grid search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eIwK3FLupSLF17uPj4UgLbyCtGQUj80Z
"""

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# Veri dosyalarının isimlerini belirt
input_files = ["WA_ValenceElectrons_standardized_normalized.txt",
               "WA_atomicradii_pm_standardized_normalized.txt",
               "WA_CovRad_standardized_normalized.txt",
               "Wa_electronegativity_standardized_normalized.txt",
               "WA_ionization_0_charge_Ev_standardized_normalized.txt",
               "WA_ionization+1charge_Ev_standardized_normalized.txt",
               "WA_ionization+2charge_Ev_standardized_normalized.txt",
               "WA_ionization+3charge_Ev_standardized_normalized.txt",
               "WA_Ionrad_standardized_normalized.txt",
               "WA_LatParb_standardized_normalized.txt",
               "WA_LatPara_standardized_normalized.txt",
               "WA_LatParc_standardized_normalized.txt", "standardized_T_normalized.txt"]

target_files = ["S.txt"]

# Her bir hedef değişkeni için model oluştur
for target_file in target_files:
    # Veriyi okuyalım
    target_data = pd.read_csv(target_file, header=None).squeeze()

    # Boş bir DataFrame oluştur, bu DataFrame'e özellikleri ekle
    features_df = pd.DataFrame()

    # Verileri sırasıyla ekle
    for input_file in input_files:
        features_df[input_file.split('_')[1]] = pd.read_csv(input_file, header=None).squeeze()

    # Veriyi eğitim ve test setlerine böl
    X_train, X_test, y_train, y_test = train_test_split(features_df, target_data, test_size=0.2, random_state=42)

    # Random Forest Regressor için grid search için hiperparametre kombinasyonları
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20, 30]
    }

    # Random Forest Regressor oluştur
    rf_model = RandomForestRegressor(random_state=42)

    # Grid search uygula
    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=5)
    grid_search.fit(X_train, y_train)

    # En iyi hiperparametreleri al
    best_params = grid_search.best_params_

    # En iyi modeli al
    best_model = grid_search.best_estimator_

    # Test seti üzerinde tahmin yap
    y_pred = best_model.predict(X_test)

    # Mean Absolute Error hesapla
    mae = mean_absolute_error(y_test, y_pred)

    # Target değerlerin ortalamasını hesapla
    target_mean = target_data.mean()

    # MAE'nin target değeri üzerindeki yüzdesini hesapla
    mae_percentage = (mae / target_mean) * 100

    # Tahmin edilen değerleri dosyaya yazdır
    predicted_file_path = f"predicted_{target_file}"
    pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).to_csv(predicted_file_path, index=False)

    # Model performansını yazdır
    print(f"\nModel for {target_file}:\n")
    print(f"Best Hyperparameters: {best_params}")
    print(f"Mean Absolute Error: {mae}")
    print(f"Target Mean: {target_mean}")
    print(f"MAE as Percentage of Target Mean: {mae_percentage:.2f}%")
    print(f"Predicted values saved to {predicted_file_path}")
    print("Feature Importances:")
    for feature, importance in zip(features_df.columns, best_model.feature_importances_):
        print(f"{feature}: {importance}")

    # Scatter plot
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=y_test, y=y_pred)

    # Unity line
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='black', linewidth=0.5, label='Unity Line')

    plt.title(f'Scatter Plot of {target_file[:-4]}: Target vs Predicted Values')
    plt.xlabel('Target Values')
    plt.ylabel('Predicted Values')
    plt.legend()  # Unity line'ı göstermek için legende ekle
    plt.show()

    # Feature importanceları bar plot olarak çiz
    plt.figure(figsize=(12, 6))
    sns.barplot(x=best_model.feature_importances_, y=features_df.columns)
    plt.title(f'Feature Importances for {target_file[:-4]}')
    plt.xlabel('Importance Score')
    plt.ylabel('Features')
    plt.show()